# Paper2Code .env file example
# Copy this file to .env and modify as needed

# IMPORTANT: When using LiteLLM, ensure you have both litellm AND any provider-specific
# dependencies installed. For AWS Bedrock, this includes boto3.

# Uncomment ONE of the following provider configurations:

# 1. AWS Bedrock Configuration
AWS_REGION=us-west-2
BEDROCK_MODEL=anthropic.claude-3-sonnet-20240229-v1:0
DISABLE_PROMPT_CACHING=0  # Set to 1 to disable caching
AWS_SHARED_CREDENTIALS_FILE=~/.aws/credentials
AWS_CONFIG_FILE=~/.aws/config
# NOTE: For AWS Bedrock, you must:
# 1. Have boto3 installed (pip install boto3)
# 2. Have valid AWS credentials configured
# 3. Have appropriate permissions to use the specified model

# 2. OpenAI
# OPENAI_API_KEY=your_api_key_here
# OPENAI_MODEL=o3-mini  # Default if not specified

# 3. Direct Anthropic API (not Bedrock)
# ANTHROPIC_API_KEY=your_api_key_here
# ANTHROPIC_MODEL=claude-3-sonnet-20240229  # Default if not specified


# Paper-specific settings (these should be set via command line args or script)
# PAPER_NAME=Transformer
# PDF_PATH=./examples/Transformer.pdf
# PDF_JSON_PATH=./examples/Transformer.json
# PDF_JSON_CLEANED_PATH=./examples/Transformer_cleaned.json
# PDF_LATEX_PATH=./examples/Transformer_cleaned.tex
# OUTPUT_DIR=./outputs/Transformer
# OUTPUT_REPO_DIR=./outputs/Transformer_repo